{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Support Vector Machines\n",
    "## Course recap\n",
    "This lab consists in implementing the **Support Vector Machines** (SVM) algorithm. \n",
    "\n",
    "Given a training set $ D = \\left\\{ \\left(x^{(i)}, y^{(i)}\\right), x^{(i)} \\in \\mathcal{X}, y^{(i)} \\in \\mathcal{Y}, i \\in \\{1, \\dots, n \\}  \\right\\}$, where $\\mathcal{Y} = \\{ 1, \\dots, k\\}$ . Recall (from lecture 7), SVM aims at minimizing the following cost function $J$:\n",
    "$$\n",
    "\\begin{split}\n",
    "J(\\theta_1, \\theta_2, \\dots, \\theta_k) \n",
    "\t&= \\sum_{i = 1}^n L_i \\\\\n",
    "\t&= \\sum_{i = 1}^n \\sum_{j \\neq y_i} \\max(0, \\theta_j^Tx^{(i)} - \\theta_{y^{(i)}}^T x^{(i)} + \\Delta)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the training set\n",
    "Let us define variables `X` and `Y` that will contain the features $\\mathcal{X}$ and labels $\\mathcal{Y}$ of the training set. Again, we will be having an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "k_classes = 2\n",
    "X = [[1., 50.], [1., 76.], [1., 26.], [1., 102.]]\n",
    "Y = [1, 2, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this simple example, the dimensionality is $d = 1$ (which means 2 features: don't forget the intercept!) and the number of samples is $n = 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prediction function\n",
    "**Exercise**: Define a function `score` that takes as parameter *the feature vector* $x$ as well as *a model* $\\theta$ and outputs the score:\n",
    "$$ h(x) = \\theta^T x = \\sum_{j = 0}^d \\theta_j x_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score(x, theta):\n",
    "    d = len(x)\n",
    "    thetaTx = 0\n",
    "    for idx in range(d):\n",
    "        print \"x \" + str(x)\n",
    "        print \"theta \" + str(theta)\n",
    "        thetaTx += x[idx] * theta[idx]\n",
    "    return thetaTx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the cost function\n",
    "### Cost function on a single sample\n",
    "**Exercise**: Define a function `cost_function` that takes as parameter *the predicted label* $y$ and *the actual label* $\\hat{y}$ of a single sample and returns the value of the cost function for this pair. Recall from lectures 1 and 2 that it is given by:\n",
    "$$ L_i = \\sum_{j \\neq y_i} \\max(0, \\theta_j^Tx^{(i)} - \\theta_{y^{(i)}}^T x^{(i)} + \\Delta) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cost_function(x, y, thetas, delta):\n",
    "    thetayTx = predict(x, thetas[y])\n",
    "    loss = 0\n",
    "    d = len(x)\n",
    "    for j in range(d):\n",
    "        if j is not y:\n",
    "            print \"x \" + str(x)\n",
    "            print \"thetas \" + str(thetas)\n",
    "            thetajTx = predict(x, thetas[idx])\n",
    "            loss += max(0, thetajTx - thetayTx + delta)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to compute the loss for a single training sample, we can get the total cost.\n",
    "\n",
    "**Exercise**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cost_function_total(X, Y, thetas, delta):\n",
    "    cost = 0 # initialize the cost with 0\n",
    "    n = len(Y)\n",
    "    for i in range(n): # iterate over the training set\n",
    "        x = X[i] # get the ith feature vector\n",
    "        y = Y[i] # get the ith label\n",
    "        print \"x \" + str(x)\n",
    "        print \"y \" + str(y)\n",
    "        print \"thetas \" + str(thetas)\n",
    "        cost += cost_function(x, y, thetas, delta) # add the cost of the current sample to the total cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_thetas(X, k_classes):\n",
    "    d = len(X[1])\n",
    "    theta = [0] * d\n",
    "    return [theta] * k_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thetas_0 = initialize_thetas(X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(x, thetas):\n",
    "    k_classes = len(thetas)\n",
    "    prediction = 0\n",
    "    highest_score = score(x, thetas[prediction]) # initialize with the first class\n",
    "    for idx_class in range(k_classes):\n",
    "        class_score = score(x, thetas[idx_class])\n",
    "        if class_score > highest_score:\n",
    "            prediction = idx_class\n",
    "    return prediction + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X[0], thetas_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_vectors(x1, x2):\n",
    "    d = len(x1)\n",
    "    sum_vector = x1\n",
    "    for idx in range(d):\n",
    "        sum_vector[idx] += x2[idx]\n",
    "    return sum_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradients(x, y, thetas, delta):\n",
    "    d = len(x)\n",
    "    k_classes = len(thetas)\n",
    "    predicted_class = predict(x, thetas)\n",
    "    grads = [[0] * d] * k_classes # initialize a list of k_class gradients with zeros everywhere\n",
    "    for idx_class in range(k_classes): # iterate over all the classes to compute the gradient for each class\n",
    "        # there are 2 formulas: one for the true class (given by 'y') and another one for the other classes\n",
    "        if idx_class + 1 == y: # if idx_class is equal to the actual class\n",
    "            p = 0\n",
    "            for j in range(k_classes):\n",
    "                if j + 1 != y: # are counting over the classes different than the actual class\n",
    "                    if score(x, thetas[j]) - score(x, thetas[y - 1]) + delta > 0:\n",
    "                        p += 1\n",
    "            for idx in range(d):\n",
    "                grads[idx_class][idx] = - p * x[idx]\n",
    "        else: # if idx_class is not the actual class\n",
    "            if score(x, thetas[idx_class]) - score(x, thetas[y - 1]) + delta > 0:\n",
    "                for idx in range(d):\n",
    "                    grads[idx_class][idx] = x[idx]\n",
    "            # we do not need an else statement here because the gradient would be equal to 0 in this case, \n",
    "            # and the gradient has been initialized with zeros\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "[[1.0, 50.0], [1.0, 50.0]]\n"
     ]
    }
   ],
   "source": [
    "print gradients(X[0], Y[0], thetas_0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_total(X, Y, thetas, delta):\n",
    "    n = len(Y) # number of training samples\n",
    "    d = len(X[1])\n",
    "    k_classes = len(thetas)\n",
    "    grads_sum = [[0] * d] * k_classes \n",
    "    for i in range(n):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        grads = gradients(x, y, thetas, delta)\n",
    "        for j in range(k_classes):\n",
    "            grads_sum[j] = sum_vectors(grads[j], grads_sum[j])\n",
    "    return grads_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7.0, 250.0], [7.0, 250.0]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_total(X, Y, thetas_0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def axpb(a, x, b):\n",
    "    d = len(x)\n",
    "    sum_vector = b\n",
    "    for idx in range(d):\n",
    "        sum_vector[idx] += a * x[idx]\n",
    "    return sum_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, delta, learning_rate):\n",
    "    k_classes = len(set(Y))\n",
    "    thetas = initialize_thetas(X, k_classes)\n",
    "    for i_iter in range(5):\n",
    "        grads = gradient_total(X, Y, thetas, delta)\n",
    "        for j in range(k_classes):\n",
    "            thetas[j] = axpb(-learning_rate, grads[j], thetas[j])\n",
    "        print \"X \" + str(X)\n",
    "        cost = cost_function_total(X, Y, thetas, delta)\n",
    "        print \"iteration \" + str(i_iter) + \", cost = \" + str(cost)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 50.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 76.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 26.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "x [1.0, 102.0]\n",
      "theta [0, 0]\n",
      "X [[1.0, 50.0], [1.0, 76.0], [1.0, 26.0], [1.0, 102.0]]\n",
      "x [1.0, 50.0]\n",
      "y 1\n",
      "thetas [[-1.4000000000000001, -50.0], [-1.4000000000000001, -50.0]]\n",
      "x [1.0, 50.0]\n",
      "theta -1.4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-4cfe020dff77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-a546b746ba29>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(X, Y, delta, learning_rate)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxpb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"X \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_function_total\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"iteration \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_iter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", cost = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-1fc7af27c165>\u001b[0m in \u001b[0;36mcost_function_total\u001b[0;34m(X, Y, thetas, delta)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"y \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"thetas \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add the cost of the current sample to the total cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-c0be643ef81d>\u001b[0m in \u001b[0;36mcost_function\u001b[0;34m(x, y, thetas, delta)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mthetayTx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-c60b0103f824>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x, thetas)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mk_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mhighest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# initialize with the first class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mclass_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-f21a6d232477>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(x, theta)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"x \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"theta \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mthetaTx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthetaTx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "gradient_descent(X, Y, 5.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
